# =========================
# DATASET CONFIGURATION
# =========================
dataset:
  train_csv: "/home/sieut/kronus/data/si/train.csv"
  val_csv: "/home/sieut/kronus/data/si/dev.csv"
  pose_pkl: "/home/sieut/kronus/data/pose_data_isharah1000_hands_lips_body_May12.pkl"
  delimiter: ","
  min_len: 32
  max_len: 1000
  additional_joints: true
  augment: true
  augment_prob: 0.5
  tokenizer_type: "seq2seq"   # "ctc" hoặc "seq2seq"

# =========================
# MODEL CONFIGURATION
# =========================
model:
  name: "CSLRTransformerAutoregressivePermutate"
  input_dim: 172   # Số joints * 2 (nếu pose là [B, T, 43, 2] thì 43*2=86)
  hidden_dim: 512
  num_layers: 2
  encoder_num_heads: 8
  decoder_num_heads: 8
  num_decoder_layers: 1
  dec_mlp_ratio: 4
  refine_iters: 3
  conv_channels: 512
  mlp_hidden: 512
  dropout: 0.1
  max_input_len: 1000    # <-- Độ dài sequence đầu vào (encoder)
  max_output_len: 12    # <-- Độ dài sequence đầu ra (decode/inference)

# =========================
# TRAINER CONFIGURATION
# =========================
trainer:
  batch_size: 8
  num_workers: 8
  epochs: 100
  lr: 0.00005
  weight_decay: 0.01
  warmup_pct: 0.1
  device: "cuda"
  seed: 42
  pretrained: "/home/sieut/kronus/logs/CSLRTransformerAutoregressivePermutate/runs_20250603_203826/version_0/checkpoints/epoch=242-val_loss=val_loss=0.4476-val_wer=val_wer=7.2220.ckpt"
  # save_dir: "./checkpoints/"
  log_interval: 50
  # log_interval_step: 100
  check_val_every_n_epoch: 1
  devices: 1
  train_refine_epoch: 100 # trong 20 epoch cuối sẽ train full model refine
# =========================
# LOGGING & MISC
# =========================
logging:
  log_dir: "./logs_refine"
  print_config: true
